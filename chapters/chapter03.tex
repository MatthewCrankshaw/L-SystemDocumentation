

\lettrine[lines=3]{T}{}here are two major parts necessary to procedurally generate plant-life using L-systems. These are the L-system rewriter and the L-system interpreter. The L-system rewriters' purpose is to take a L-system file as input. The input is read, processed and understood generating the necessary structures and information in order to carry out the final rewriting process. This eventually gives a resulting string of modules which can be passed to the interpreter. The interpreter goes through each module and processes it as an instruction for the turtle graphics interpreter. Which will eventually result in a model of a plant on the screen.

This chapter will focus on the first major part of this process, the rewriting system. Due to the complexity of the L-system grammar, it is difficult for a computer to properly understand the L-system language. This understanding is required in order to carry out string rewriting effectively. This chapter will introduce a technique of processing the L-system input which simplifies the rewriting process, using a technique that is similar to how computer languages are compiled before executing. Using a \say{compiler} to process an L-system means that the L-system \say{program} can be broken down into a three stage process. The first stage is the \textit{lexical analysis} of the L-system input, then a process called \textit{parsing} and finally is string rewriting. Each component of the L-system will be analysed and parsed into the appropriate computational structures. If the syntax of the L-system is valid and parsing is successful, the structures created will be used to rewrite the L-systems' axiom. If the L-system provided does not match the context-free grammar, an appropriate error message can be displayed, stating where the syntax error occured and what was incorrect. This concept borrows from ideas similar to that of a compilation error of a computer language.

For a simple D0L-system like the one seen in section \ref{DOL-system example}. Each symbol is made up of a single character, and because the D0L-system is deterministic, there is no randomess when determining a matching rule. It is therefore relatively easy to create a rewriting system capable of understanding the DOL-system, it is just a case of storing the starting string and production rules. Then iterating through the string one character at a time and matching the symbol to a rule, if a match is found, the symbol is replaced with the string provided by the rule. This can be implemented relatively simply, however, to implement the parametric 0L-system, where each instruction is a module with potentually multiple parameters and each parameter could be a mathematical expression, the rewriting system will have to better understand what each part of the L-system is specifying based on the grammar and its context in the L-system. The lexical analyser and parser can be used for this purpose in order to classify each part of the L-system and prepare it for rewriting.

\begin{figure}[htbp]
	{\centering
		\setlength{\fboxrule}{1pt}
		\vspace{7px}
		\fbox{
			\includegraphics[scale=0.32]{Diagrams/StringRewriter.png}
		}
		\caption{Diagram of the Parts of The Rewiting System.} \label{3D rotations}
	}
\end{figure}
\FloatBarrier

The rewriting system, refers to three specific parts, as seen in the diagram above. The L-system input is passed to the rewriter in the form of a file, or string of text, this string of text is then processed by the lexical analyser, the result of the lexical analyser is a set of syntactic categories which is used by the parser to create the relvent data structures and syntax tree, this information is then used by the string rewriter which finally produces the resultant string that can be interpreted by a domain specific interpreter. Each part of the L-system rewriter will be explained in more detail in following sections.

\section{Environment and Tools}


This majority of the implementation of the L-system will be written in the C and C++ programming languages \cite{stroustrup2000c++}, and I will be using the modern Open Graphics Library or \gls{OpenGL}. The OpenGl framework is one of the industry standards for creating 3D graphics applications, and is a cross platform API for interacting with the \acrshort{gpu} in a low level way. The low level nature of OpenGL is important as some of the structures and models we are going to be displaying and simulating can be graphically intensive \cite{sellers2013opengl} \cite{movania2017opengl}. OpenGL was originally intended to be an \acrshort{api} for the C and C++ programming languages, and therefore we can have a programming language and graphics API which have a strong emphasis on performance.

There are also a number of libraries which will provide some extra functionality. The standard library for C and C++ provides many usefull structures and functions which will be incredibly usefull during the development process. For more specialised mathematics capabilities the \acrfull{glm} library holds many mathematics classes and functions for conveniently dealing with some 3D mathematics such as vectors, matrices and quaternions. Another important library is the \acrfull{glfw} which is a multiplatform \acrshort{api} for creating an managing user interface windows, events and user input \cite{glfwDocumentation}.

In order to keep track of changes and manage versions Git is a free and open source version control software, that is able to keep track of changes that have been made to the files within a project folder. It will be used to keep track of previous versions of the project throughout the development process. Git can be used in conjuction with Github, which is a online web application that stores git repositories. This acts as a backup as well as containing all previous versions of the project \cite{torvalds}.

\section{The L-system as an interpreted grammar}

Traditionally an interpreter in computing is a program that takes program code as input, where it is then analyzed and interpreted as it is encountered in the execution process. All of the previously encountered information is kept for later interpretations. The information about the program can be extracted by inspection of the program as a whole, such as the set of declared variables in a block, a function, etc \cite{wilhelm2010compiler}. In essence, the L-system rewriter contains a type of interpreter, this should not be confused with the interpreter that processes the resultant string using turtle graphics. Due to this confusion of terms I will refer the system containing the lexical analyser, L-system parser and the string rewriter as the L-system rewriter, instead of an interpreter in the computational sense. 

A similarity can be drawn between traditional interpreted languages and the L-system rewriter. The L-system rewriter defines a set of constant variables, a starting point and then some production rules. This information can then be used to rewrite the starting string a number of times. Later on, it may be decided that, instead of five generations of rewriting, the rewriter should instead generate ten rewrites. Some information about the L-system is still valid, the production rules, axiom and constants have not changed and therefore, this information can be used in order to interpret to the tenth generation instead. This can be used to go from the current state of the L-system rewriter and just rewrite another five times. Instead of throwing all the information away and starting from scratch. Furthermore, if we would like to retrieve the resultant string, this can simply be asked for from the L-system rewriter. 

The lexical analyser and parser are a neccessary part in order to carry out rewriting. Without them it would be difficult to find the syntactic roles of each part of the L-system, take the module: F(2*3, x * (2 + y)) as an example, here there is a single module with two parameters, one parameter has the expression (2 * 3) and the other has the expression (x * (2+y)), these complex structures within a grammar require knowledge about the structure of the grammar it represents. The lexical analyser firstly makes sure that all the syntax within the L-system is correct and assigns each word or symbol to a syntactic category, the parser then splits the L-system into its component parts and is describes each parts syntactic roll. This provides the understanding that x and y are variables within a module and do not represent another module, as well as where the values of x and y could be found. 

The trade off of creating an L-system with more complexity within the grammar itself is that it become more difficult to write a valid L-system to represent a particular structure, the advantage of using an rewriter specifically designed for a \acrshort{cfg} like the parametric 0L-system grammar is that it can make it simpler to debug any syntactic errors within an L-system, as well as make the string rewriting much faster. This means that writing a L-system becomes simlar to rewriting a recursive program and any syntactic mistakes made in writing this \say{program} results in a meaningful error describing what was incorrect. 

\section{The Syntax of a Parametric L-system}

This section will cover the valid syntax for the parametric L-system rewriter, the syntax for the parametric 0L-system is similar to the definition of the L-systems given by Prusinkiewicz and Lindenmayer in section \ref{definition of a parametric 0L-system section}, this is to keep consistant with how most L-systems are defined. There are some additions and modifications to the syntax definition provided by Prusinkiewicz and Lindenmayer in order to construct a L-system that includes branching, constant variable definitions, object specifications, parametric L-system concepts, randomness as well as stochastic L-systems \cite{prusinkiewicz2012algorithmic}. 

This parametric 0L-system is made up of five major parts, each part can be catagorised as a statement, these statements are the define statements, include statements, a single generation statement, a single axiom statement and a one or more production rule statements \cite{prusinkiewicz2013lindenmayer}. All of these statements collectively form a parametric 0L-system. Each statement starts with a \# character and ends with a ; character, this is useful to the lexer and parser and allows two statements to be written on the same line. 

The order of statements should be listed as follows: 

\begin{equation} \label{statement order example}
\begin{aligned}
	&\text{\#generations statement;}\\
	&\text{\#define statements;}\\
	&\text{\hspace{10mm}...}\\
	&\text{\#include statements;}\\
	&\text{\hspace{10mm}...}\\
	&\text{\#axiom statement;}\\
	&\text{\#production statements;}\\
	&\text{\hspace{10mm}...}\\
\end{aligned}
\end{equation}

The order for some of statments does not necessarily matter, such as the generations statement which can be defined anywhere within the L-system, however, there are some parts that are required to be in a particular order, for instance, the define and include statements must appear above the axiom and productions statements as they define values used within the axiom and production rules. It is best practice to specify the L-system in the above order as to avoid any conflictions or errors. 

Another design decision that has been made, is that all numbers within the L-system are repersented as floating point numbers. Other data types could be added to the definition of the L-system in the future, however, there is some added complexities in doing so, such as the conversion from one type to another, or having to specify which data type a variable represents. For all intents and purposes, the floating point data type provides all the neccessary functionality needed for the L-system, therefore, it seems unnecessary to add extra data types. 

\section{The L-system Lexical Analyser} \label{Flex}

D. Cooper and L. Torczon write that "The scanner, or lexical analyser, reads a stream of characters and produces a streeam of words. It aggregates characters to form words and applies a set of rules to determin wheter or not each word is legal in the source language. If the word is valid, the scanner assigns it a syntactic category, or part of speech" \cite{cooper2011engineering}. The lexer for parametric 0L-system will need to do exactly that. To get to a stage where we can successfully rewrite the L-system string, the rewriter must first understand what each word and symbol represents, in the form of a syntactic category, and whether or not the word or symbol is valid or not. 

It is possible to write custom \gls{Lexer}, however, it can be quite complicated and time consuming to design and implement, and once a custom \gls{Lexer} has been created it can be difficult to change functionality at a later stage. Luckely there is a well known program known as the \acrlong{flex} (\acrshort{flex}), \acrshort{flex} takes in a file which contains the lexical rules of the language, it uses these rules to create a \gls{Lexer} program. When \acrshort{flex} is run it will create a \gls{Lexer} in the form of a C program. We can use the generated Lexer on the L-system that we would like to rewrite, taking the word within the L-system and assigning a syntactic category to it. In order to create a lexer with \acrshort{flex}, the lexical rules in the form of syntactic categories must defined. Below are the valid syntactic categories of a parametric 0L-system:

\begin{table}[h!] \center
\begin{tabular}{ | c | l | l |}
\hline
	Syntactic Word	& Syntactic Category & Meaning\\  
\hline
\hline
	, 				& T\_COMMA 				& Separation between module parameters \\
\hline
	: 				& T\_COLON 				& Separation between production rule parts \\
\hline
	; 				& T\_SEMI\_COLON 		& End of a statement\\
\hline
	\#				& T\_HASH 				& Beginning of a statement\\
\hline
	( 				& T\_PARENL 			& Start of a modules parameters \\
					&						& or specifies presidence in an expression \\
\hline
	) 				& T\_PARENR 			& End of a modules parameters \\
					&						& or specifies presidence in an expression \\
\hline 
	\{ 				& T\_BRACKETL 			& Start of a random range\\
\hline
	\} 				& T\_BRACKETR 			& End of a random range\\
\hline
	$\sim$ 			& T\_TILDE 				& Stochastic operator\\
\hline
	== 				& T\_EQUAL\_TO 			& Relational operator stating equal to\\
\hline
	!= 				& T\_NOT\_EQUAL\_TO 	& Relational operator for not equal to\\
\hline		
	$<$ 			& T\_LESS\_THAN 		& Relational operator for less than\\
\hline
	$>$ 			& T\_GREATER\_THAN 		& Relational operator for greater than\\
\hline
	$<$ = 			& T\_LESS\_EQUAL 		& Relational operator for greater or equal\\
\hline
	$>$ = 			& T\_GREATER\_EQUAL 	& Relational operator for greater or equal\\
\hline
	[ 				& T\_SQUARE\_BRACEL 	& Module name (branching save state) \\
\hline
	] 				& T\_SQUARE\_BRACER 	& Module name (branching load state) \\
\hline
	+ 				& T\_PLUS 				& Arithmetic operator for addition, or\\
					&						& Module name (Yaw right) \\
\hline
	- 				& T\_MINUS 				& Arithmetic operator for subtraction, or\\
					&						& Module name (Yaw left)\\
\hline
	/ 				& T\_FORWARD\_SLASH 	& Arithmetic operator for division, or\\
					&						& Module name (Pitch up)\\
\hline
	$\backslash$ 		& T\_BACK\_SLASH 		& Module name (Pitch down)\\
\hline
	* 				& T\_STAR 				& Arithmetic operator for multiplication, or\\
					&						& Condition in a production rule which is true\\
\hline
	$\land$		& T\_HAT 				& Arithmetic operator for and exponent, or\\
					&						& Module name (Roll right)\\
\hline
	$\&$ 			& T\_AMPERSAND 			& Module name (Roll left)\\
\hline
	! 				& T\_EXCLAMATION 		& Module name (Set size of branch)\\
\hline
	\$ 				& T\_DOLLAR 			& Module name \\
\hline
	= 				& T\_ASSIGN 			& Assignment operator used to set generations\\
\hline
	\#n 			& T\_GENERATIONS 		& Declaration of the number of generations\\
\hline
	\#w 			& T\_AXIOM 				& Declaration of the axiom\\
\hline
	\#define 			& T\_DEFINE 		& Declaration of the define\\
\hline
	\#object 			& T\_OBJECT			& Declaration of the object\\
\hline
	[0-9]+.[0-9]+$|$[0-9]+ 					& T\_FLOAT 				& Regular expression for a floating point number\\
\hline
	[a-zA-Z\_][a-zA-Z0-9\_]*  				& T\_VAR\_NAME 			& Regular expression for a module or variable name\\
\hline
\hline
\end{tabular}
\caption{Table of Valid Lexer Words}
\label{lexer words}
\end{table}
\FloatBarrier

From the table above there are a number syntactic categories which contain more than one meaning to the grammar, for instance the ( and ) parenthesis have two meanings, it is either to specify the begining and end of a modules parameters or it specifies presidence within an expression.  It is not up to the scanner to determine what the each particular parentheses means, or that it has a meaning at all, the lexer only recognises that it falls into the syntactic categories, T\_PARENL and T\_PARENR. Deriving the meaning of a given token or sytactic category is left up to the parser which is more aware of the context of each syntactic word. Similarly, the symbols [,],+,-,/,$\backslash$, $\land$, $\&$, ! and \$ are valid module names; Moreover, it is possible for a T\_VAR\_NAME to also be a module name, these symbols need to be specifically defined as their own syntactic category, as they not only represent a module name but can also represent a different meaning depending on their context. For instance, the +, -, / are valid module names, but they also are mathematical symbols used within an arithmetic expression. The scanner must separate these symbols and keep them in their own syntactic category in order for the parser to be able to understand the same symbol in multiple contexts. 


It is also important to note that there are two special types of tokens, these being the T\_FLOAT and T\_VAR\_NAME which not only are part of a syntactic category but also contain a value, for instance T\_FLOAT has a floating point value and T\_VAR\_NAME has a string value. These values must be kept and provided to the parser.

\section{The L-system Parser} \label{parser}

The parsers job is to find out if the input stream of words from the \gls{Lexer} makes up a valid sentence in the language. The \gls{Parser} fits the syntactical category to the grammatical model of the language. If the \gls{Parser} is able to fit the syntactical category of the word to the grammatical model of the language then the syntax is seen to be correct. If all of the syntax is correct the \gls{Parser} will output a syntax tree and build the data structures for use later on in the compilation process \cite{cooper2011engineering}. For the L-system rewriter the syntax tree and data structures are not used for compilation but rather for the string string rewriting process.

In order describe the a grammar, there needs to be a suitable notation to express its syntactic structure. According to Cooper the \acrlong{bnf} (\acrshort{bnf}) has traditionally been used by computer scientists to represent context-free grammers such as programming languages, its origins are from the late 1950s and early 1960s. The \acrshort{bnf} notation represents the context-free grammar by defining a set of non-terminal symbols that derives from a set of terminal or non-terminal symbols. Terminal symbols are elementary symbols of the language definied by the formal grammar, a terminal symbol will eventually appear in the resulting formal language. On the other hand a non-terminal symbol exists only as a placeholder for patterns of terminal symbols, but does not appear within the formal language itself. The syntactic convension for a \acrshort{bnf} is for non-terminal symbols to be surrounded by angled brackets for instance $<$expression$>$ and terminal symbols, such as the symbol for addition \say{+} to be underlined, but nowadays it is not often underlined. The symbol $\epsilon$ represents an empty string, the ::= means \say{derives} and the $\mid$ means \say{also derives} but is often articulated as an \say{or} \cite{cooper2011engineering}. In order to derive a sentence of text within a language the very first derivation must be a non-terminal symbol called the goal symbol, the goal symbol is a set of all valid derived strings, this means that the goal symbol is not a word within the language, but a syntactic variable in the form of a non-terminal symbol. The \acrshort{bnf} notation below can be used to represent a simple grammar for arithmetic expressions, where the terminal \say{number} is any valid integer and the goal symbol is $<$expression$>$.\\
\\
\noindent
Below is the \acrshort{bnf} notation for the syntax of an arithmetic expression for addition and subtraction:
\begin{algorithm}
\begin{bnf*}
	\bnfprod{expression}
		{\bnfts{number}}\\
		\bnfmore{\bnfor \bnfts{(} \bnfpn{expression} \bnfts{)}}\\
		\bnfmore{\bnfor \bnfpn{expression} \bnfts{+} \bnfpn{expression}}\\
		\bnfmore{\bnfor \bnfpn{expression} \bnfts{-} \bnfpn{expression}}
\end{bnf*}
\end{algorithm}
\FloatBarrier

The above \acrshort{bnf} states that the non-terminal $<$expression$>$ derives from a terminal number, or an expression contained within two parenthesis, or two expressions either side of an addition terminal symbol, or two expressions either side of a subtraction terminal symbol. This type of notation is recursive in nature and allows the formal language to write expressions which exist within other expressions, for example the expression \say{5 + 10 - (20 + 2)}. \\

\subsection{\acrlong{bnf} of the L-system Grammar} \label{L-system Grammar}

	\begin{bnf*}
	\bnfprod{lSystem}
		{\bnfes \bnfor \bnfpn{statements} \bnfsp \bnfts{EOF}}\\
	\bnfprod{statements}
		{\bnfes \bnfor \bnfpn{statement} \bnfpn{statements}}\\
	\bnfprod{statement}
		{\bnfts{EOL} \bnfor \bnfpn{generation} 
		\bnfor \bnfpn{definition} 
		\bnfor \bnfpn{object} 
		\bnfor \bnfpn{axiom} 
		\bnfor \bnfpn{production}}\\
	\bnfprod{generation}
		{\bnfts{\#define} \bnfsp \bnfts{=} \bnfsp \bnfpn{float} \bnfts{;}}\\
	\bnfprod{float}
		{\bnfts{[0-9]+.[0-9]+$|$[0-9]+}}\\
	\bnfprod{variable}
		{\bnfts{[a-zA-Z\_][a-zA-Z0-9\_]*}}\\
	\bnfprod{number}
		{\bnfpn{float} \bnfor \bnfts{-} \bnfsp \bnfpn{float}}\\
	\bnfprod{range}
		{\bnfts{\{} \bnfpn{number} \bnfts{,} \bnfpn{number} \bnfts{\}}}\\
	\bnfprod{definition}
		{\bnfts{\#define} \bnfsp \bnfpn{variable} \bnfsp \bnfpn{number} \bnfts{;}}\\
	\bnfprod{object}
		{\bnfts{\#object} \bnfsp \bnfpn{variable} \bnfsp \bnfpn{variable} \bnfts{;}}\\ 
	\bnfprod{module}
		{\bnfpn{variable} \bnfor \bnfts{+} 
		\bnfor \bnfts{-} 
		\bnfor \bnfts{/} 
		\bnfor \bnfts{$\backslash$} 
		\bnfor \bnfts{$\land$}
		\bnfor \bnfts{\&}
		\bnfor \bnfts{\$}
		\bnfor \bnfts{[}
		\bnfor \bnfts{]}
		\bnfor \bnfts{!}}\\
		\bnfmore{\bnfor \bnfts{+} \bnfts{(} \bnfpn{param} \bnfts{,} \bnfsp \bnfpn{paramList} \bnfts{)}}\\
		\bnfmore{\bnfor \bnfts{-} \bnfts{(} \bnfpn{param} \bnfts{,} \bnfsp \bnfpn{paramList} \bnfts{)}}\\
		\bnfmore{\bnfor \bnfts{/} \bnfts{(} \bnfpn{param} \bnfts{,} \bnfsp \bnfpn{paramList} \bnfts{)}}\\
		\bnfmore{\bnfor \bnfts{$\backslash$} \bnfts{(} \bnfpn{param} \bnfts{,} \bnfsp \bnfpn{paramList} \bnfts{)}}\\
		\bnfmore{\bnfor \bnfts{$\land$} \bnfts{(} \bnfpn{param} \bnfts{,} \bnfsp \bnfpn{paramList} \bnfts{)}}\\
		\bnfmore{\bnfor \bnfts{\&} \bnfts{(} \bnfpn{param} \bnfts{,} \bnfsp \bnfpn{paramList} \bnfts{)}}\\
		\bnfmore{\bnfor \bnfts{\$} \bnfts{(} \bnfpn{param} \bnfts{,} \bnfsp \bnfpn{paramList} \bnfts{)}}\\
		\bnfmore{\bnfor \bnfts{[} \bnfts{(} \bnfpn{param} \bnfts{,} \bnfsp \bnfpn{paramList} \bnfts{)}}\\
		\bnfmore{\bnfor \bnfts{]} \bnfts{(} \bnfpn{param} \bnfts{,} \bnfsp \bnfpn{paramList} \bnfts{)}}\\
		\bnfmore{\bnfor \bnfts{!} \bnfts{(} \bnfpn{param} \bnfts{,} \bnfsp \bnfpn{paramList} \bnfts{)}}\\
	\bnfprod{axiom}
		{\bnfts{\#w} \bnfsp \bnfts{:} \bnfsp \bnfpn{axiomStatementList} \bnfts{;}}\\
	\bnfprod{axiomStatementList}
		{\bnfes \bnfor \bnfpn{axiomStatement} \bnfpn{axiomStatementList}}\\
	\bnfprod{axiomStatement}
		{\bnfpn{module}}\\
	\bnfprod{paramList}
		{\bnfes \bnfor \bnfpn{param} \bnfpn{paramList}}\\
	\bnfprod{param}
		{\bnfpn{expression}}\\
	\bnfprod{expression}
		{\bnfpn{variable} \bnfor \bnfpn{number} \bnfor \bnfpn{range}}\\
		\bnfmore{\bnfor \bnfpn{expression} \bnfts{+} \bnfpn{expression}}\\
		\bnfmore{\bnfor \bnfpn{expression} \bnfts{-} \bnfpn{expression}}\\
		\bnfmore{\bnfor \bnfpn{expression} \bnfts{*} \bnfpn{expression}}\\
		\bnfmore{\bnfor \bnfpn{expression} \bnfts{/} \bnfpn{expression}}\\
		\bnfmore{\bnfor \bnfpn{expression} \bnfts{$\land$} \bnfpn{expression}}\\
		\bnfmore{\bnfor \bnfts{(} \bnfpn{expression} \bnfts{)}}\\
	\bnfprod{production}
		{\bnfts{\#} \bnfpn{variable} \bnfsp \bnfts{:} \bnfsp \bnfpn{predecessor} \bnfsp \bnfts{:} \bnfsp \bnfpn{condition} \bnfsp \bnfts{:} \bnfsp \bnfpn{successor} \bnfts{;}}\\
	\end{bnf*}

\newpage

\begin{bnf*}
	\bnfprod{predecessor}
		{\bnfpn{predecessorStatementList}}\\
	\bnfprod{predecessorStatementList}
		{\bnfes \bnfor \bnfpn{predecessorStatement} \bnfpn{predecessorStatementList} }\\
	\bnfprod{predecessorStatement}
		{\bnfpn{module}}\\
	\bnfprod{condition}
		{\bnfts{*}}\\
		\bnfmore{\bnfor \bnfts{$\sim$} \bnfpn{float}}\\
		\bnfmore{\bnfor \bnfpn{leftExpression} \bnfpn{operator} \bnfpn{rightExpression}}\\
	\bnfprod{leftExpression}
		{\bnfpn{expression}}\\
	\bnfprod{rightExpression}
		{\bnfpn{expression}}\\
	\bnfprod{operator}
		{\bnfts{==} \bnfor \bnfts{!=} \bnfor \bnfts{$<=$} \bnfor \bnfts{$>=$} \bnfor \bnfts{$>$} \bnfor \bnfts{$<$}}\\
	\bnfprod{successor}
		{\bnfpn{successorStatementList}}\\
	\bnfprod{successorStatementList}
		{\bnfes \bnfor \bnfpn{successorStatement} \bnfpn{successorStatementList}}\\
	\bnfprod{successorStatement}
		{\bnfpn{module}}\\
\end{bnf*}

\noindent
As seen above in the \acrshort{bnf} notation for a L-system, the goal state is $<$lSystem$>$. The $<$lSystem$>$ can be made up of $<$statements$>$ beginning with the symbol \say{\#} and ending with the symbol \say{;}, or the \acrlong{eof} (\acrshort{eof}) character signifying the end of the L-system. Each non-terminal $<$statements$>$ is made up of a $<$statement$>$ followed by more $<$statements$>$, or an empty string ($\epsilon$). The $<$statement$>$ itself can either be an \acrlong{eol} (\acrshort{eol}) character or a $<$generation$>$, $<$definition$>$, $<$object$>$, $<$axiom$>$ or $<$production$>$ statement. The non-terminal symbols $<$float$>$ and $<$variable$>$ specify a regular expression. Each statement then has a number of terminal and non-terminal derivatives that allow the production of all valid L-systems that follow this grammar. 

In the previous chapter the scanner definined the syntactic categories, these syntactic categories are in fact all the valid terminal symbols within the L-system grammar. In essence the parser takes these syntactic categories and finds if they fit the above \acrshort{bnf} and if so, it extracts the information from the L-system and generates the relavent data structures and syntax tree. 


\subsection{Constants and Objects}

Defining constants and objects is similar syntactically, the keyword define or include is used, followed by a variable name followed by a value, the value for a constant is a floating point number and the value for an include is a name of an object within the predefined object library. An example of the defining a constant and an object can be seen below: 

\begin{equation} \label{constant and object example}
\begin{aligned}
	&\text{\#define num 10;}\\
	&\text{\#define pi 3.1415;}\\
	&\\
	&\text{\#include F BRANCH;}\\
	&\text{\#include S SPHERE;}\\
\end{aligned}
\end{equation}

The definition variables can be stored as a table, called a constants table, which keeps track of all of the constant variable names as well as their values defined by the L-system, as seen in the table below: 

\begin{table}[h!] \center
\begin{tabular}{ | c | l | }
\hline
	Variable Name 	& Value\\  
\hline
\hline
	num 				& 10.0\\
\hline
	pi					& 3.1415\\
\hline
\end{tabular}
\caption{Table of turtle instruction symbols and their meaning to the interpreter}
\label{constants table}
\end{table}
\FloatBarrier

The object table structure is very similar to the constants table, the object table holds the module name, and name of the object in the predefined object library. The object table will not be used during rewriting but will be necessary to provide information during the interpretation of the resulting string about which objects each module should render. 

\begin{table}[h!] \center
\begin{tabular}{ | c | l | }
\hline
	Module Name	& Object Name\\  
\hline
\hline
	F 				& BRANCH\\
\hline
	S				& SPHERE\\
\hline
\end{tabular}
\caption{Table of turtle instruction symbols and their meaning to the interpreter}
\label{constants table}
\end{table}
\FloatBarrier

\subsection{Implementing Modules and Strings}

For the purposes of the rewriter it is important to understand that there are three major parts of a module, there is a module name, which is a string of characters or a symbol, secondly there is a list of parameters signified by open and close parenthesis, there can be zero or more parameters listed. If there are no parameters for a module you can specify it without parenthesis, however, there should then be a space between the module without parenthesis and the next module. Thirdly, each parameter can either be made up of a number, variable, random number range or a mathematical expression containing  numbers, variables and parentheses signifying precedence. 

There are two types of modules, one being a module definition and the other a module call. The module definition stands as a type of template of a module within a production rule, these templates do not have to hold actual values but the values will be substituted during the rewriting process. The module calls would appear either in the axiom or in the resultant string, the parameters of a module call will hold an actual numerical value. Below is an example outlining the difference between the module definition and module calls.

\begin{equation} \label{module definition and call example}
\begin{aligned}
	&\text{\#w : A(10);}\\
	&\text{\#p1 : A(x) : * : A(x)A(x); }\\
\end{aligned}
\end{equation}

In example \ref{module definition and call example} above, the module A(10) within the axiom, is a module call, as it contains the numerical value of 10 in the first parameter. In the production rule p1 the module A(x) within the predecessor is a module definition, it states that module A's first parmeter has a local variable x, the calling modules value will substitute x and will replace the value of x anywhere within the successor statement, p1's successor has two modules A(x)A(x), also module defintions however the value x will be subtituted with the calling modules value. When a production rules successor rewrites the calling module, the successors modules must have a numerical value, they then become module calls within the resultant string.

A string in the context of a parametric L-system is a vector of modules, the modules are linked one after the other creating a type of string, but instead of characters or symbols we have a string of modules.

\subsection{Implementing Arithmetic Expressions Trees}

As stated within the \acrshort{bnf} of the L-system grammar an expression is either a variable name, a number or a random range, it is also possible that an expression is part of another expression. Take the example: $5 \times 4 + n$, here there are three expressions 5, 4 and $n$ however, $5 \times 4$ is also an expression, as well as $4 + n$. An expression can also be described as any of the aforementioned expressions between a set of parenthesis such as $(4+n)$. The result of the expression is calculated from left to right unless the parenthesis are used which prioritises the encapsulated expression to be calculated first. We can represent this expression as an expression tree in the diagram below:


\begin{figure}[htbp]
	{\centering
		\setlength{\fboxrule}{1pt}
		\vspace{7px}
		\fbox{
			\includegraphics[scale=0.4]{Diagrams/ThesisContent.png}
		}
		\caption{Diagram of an expression tree.} \label{3D rotations}
	}
\end{figure}
\FloatBarrier

The parser provides a syntax tree, which makes it easy to generate the above expression tree, this can have four types of nodes, a variable, number, random range or a operator. The end nodes of the expression tree must be either a number, variable or random range; moreover, a connecting node within the tree must be an operator. We can then traverse the generated tree, and replace the variables with their associated value, and for random ranges we can generate the random value and assign it to the node. A second traversal during the rewriting process can then computes the result of the expression. 

\subsection{Implementing Random Ranges}

A random range provides a method of declaring a variable which represents a number that should be randomly generated between two bounds. A random range declared within a define statement will generate a random number when that constant variable is added to the constants table. A random range declared within the axiom will generate random number before the string rewriting process begins, this ensures that the number. Conversely, if a random range is defined within the successor of a production rule, the number should be generated during the rewriting process when the current module within the string is successfully matched to the predeccessor at the same time as the expressions within the successors are being evaluated. The values are generated during the rewriting process rather than prior is so that each time a module is matched to the rule, the successor will generate a different value. 

The random number is generated using a simple psuedo-random number generator which gives a uniform distribution between a minimum and a maximum value. It is possible to implement a different type of random distribution if this is something required by the problem domain, however for the purposes of generating plant-life a uniform distribution should be sufficient. 

\subsection{Implementing Stochastic Rules}

Each rule belonging to a stochastic group of rules provides a probabity value of how likely it is that the particular rule is selected during the rewriting process. For production rules to be part of the same stochastic group they are required to meet four criteria: 

\begin{itemize}
\item The stochastic operator $\sim$ must be used with a probability between 0.0 and 1.0.
\item The predecessor module name must match the other predecessor module names within that stochastic group.
\item The number of parameters within the predecessor must match the number of parameters of other production rules within that stochastic group.
\item The total probability of all of the production rules within the stochastic group must not exceed 1.0 or be less than 0.0.
\end{itemize}

Each time a rule is added to a stochastic group an entry a stochastic rule table is created in order to keep track of which rules are associated with which stochastic group as well as the probability of each rule. Using the stochastic rules below, we can generate a stochastic rule table as seen in table \ref{stochastic table}. 

\begin{equation} \label{stochastic implementation example}
\begin{aligned}
	&p_1~ :  F(x)~ :~ \sim 0.33 ~ :~ F(x)[+(r)F(x)]F(x)[-(r)F(x)]F(x)\\
	&p_2~ :  F(x)~ :~ \sim 0.33 ~ :~ F(x)[+(r)F(x)]F(x)\\
	&p_3~ :  F(x)~ :~ \sim 0.34 ~ :~ F(x)[-(r)F(x)]F(x)\\
\end{aligned}
\end{equation}

\begin{table}[h!] \center
\begin{tabular}{ | c | c | c | }
\hline
	Stochastic Group & Rule Name & Probability\\  
\hline
\hline
\multirow{3}{*}{F1} & p1 & 0.33 \\
& p2 & 0.33 \\
& p3 & 0.34 \\
\hline
\end{tabular}
\caption{Table of the stochastic rules probabilities within a stochastic group.}
\label{stochastic table}
\end{table}
\FloatBarrier

The stochastic name can be generated by using the module name of the predecessor of the production rule as well as the number of parameters within the predecessor module. In the example above we can use the predecessor name F which has a single parameter, making the stochastic name F1. This serves as a unique identifier for the stochastic group. Once all of the production rules have been processed and added to the stochastic rule table, each groups probabilities should be added together and the total should equal 1.0, certain tolerences should put in place to account for floating point error. 

During the rewriting process the module that is to be rewritten will be matched to a particular stochastic group. A uniformly distributed random number is then generated between 0.0 and 1.0. A range for each rule will then be generated, for instance, p1 will be between 0.0 and 0.33, p2 will be between 0.33 and 0.66 and finally p3 will be between 0.66 and 1.0. The production rule with the range that the random number falls between is then selected and used for rewriting. 

\section{The String Rewriter}

Once the L-system has been processed by both the lexical analyser and the parser, the data structures and information, such as the starting string, constant variables and production rules are set up for the string rewriter. The string rewriter, is the final stage which uses this data by starting with a current string of modules which is originally set to the axiom string. The string rewriter will then iterate over each module within the current string carrying matching it to the production rules and rewriting the module with the successor if the production rule matches. Once all of the modules have been rewritten, the current string is replaced by the result string for that iteration. This process is carried out for the number of generations specified within the L-system and will eventually provide the resultant string of modules.

\newpage
\begin{algorithmic}[1]
\Procedure{rewriter}{N, A}
\Statex
\Ensure N $>$ 0																	\Comment{The number of generations to rewrite}
\Ensure A $\not=$ empty															\Comment{A non empty Axiom, a list of modules}
\Statex
\State n $\gets$ 0
\State current $\gets$ A														\Comment{Current string of modules}
\While{n $<$ N}																	\Comment{For each generation}
	\State next $\gets$ empty list
	\For{each mod in current}													\Comment{call is the calling module in current}
		\State P $\gets$ \Call{FindProductionMatch}{mod}						\Comment{P is the matching production rule}
		\If{P $\not=$ NULL}
			\State pred $\gets$ P.predecessor									\Comment{def is the defining module in predecessor}
			\For{each succ in P.successor}
				\State index $\gets$ 0
				\While{index $<$ number of predecessor parameters}
					\State \Call{AddLocalVar}{pred.param[index], mod.param[index]}
					\State index $\gets$ index + 1
				\EndWhile
				\State copy $\gets$ succ 										\Comment{Create a deep copy}
				\For{each parameter in copy}									\Comment{parameter is an expression tree}
					\State \Call{ReplaceVariables}{parameter}
					\State \Call{EvaluateExpression}{parameter}
				\EndFor
				\State next $\gets$ next + copy
			\EndFor
		\Else
			\State next $\gets$ next + mod
		\EndIf
	\EndFor
	\State n $\gets$ n + 1
	\State current $\gets$ next
\EndWhile
\State \textbf{return} current
\EndProcedure
\end{algorithmic}

\newpage
\begin{algorithmic}[1]
\Function{FindProductionMatch}{Module}
\For{each P in productionTable}												\Comment{P is a production}
	\State predecessor $\gets$ P.predecessor								\Comment{predecessor is a single module}
	\If{predecessor.name $\not=$ Module.name}
		\State \textbf{continue}
	\EndIf
	\If{predecessor.numParam $\not=$ Module.numParam}
		\State \textbf{continue}
	\EndIf
	\If{P has no condition}													
		\State \textbf{return} P.name										\Comment{match found}
	\ElsIf{P has a stochastic condition}
		\State rand $\gets$ random float between 0.0 and 1.0
		\State total $\gets$ 0.0
		\State S $\gets$ list of pairs 										\Comment{pair(production name, probability value)} 
		\For{each s in S}													\Comment{Loop through each tuple in the stochasic list}
			\If{first item}
				\If{rand $\geq$ 0.0 AND rand $<$ s.value}
					\State \textbf{return} s.name
				\EndIf
			\ElsIf{last item}
				\If{rand $\geq$ total AND rand $\leq$ 1.0}
					\State \textbf{return} s.name
				\EndIf
			\Else
				\If{rand $\geq$ total AND rand $<$ total + s.value}
					\State \textbf{return} s.name
				\EndIf
			\EndIf
			\State total $\gets$ total + s.value
		\EndFor	
	\Else																	\Comment{Regular condition}
		\State left $\gets$ P.condition.left								\Comment{Deep copy left expression tree}
		\State right $\gets$ P.condition.right								\Comment{Deep copy right expression tree}
		
		\State \Call{replaceVariables}{left}
		\State \Call{replaceVariables}{right}
		
		\State \Call{evaluateExpression}{left}
		\State \Call{evaluateExpression}{right}
		
		\If{left P.condition.op right}										\Comment{Apply operator ($==$, $\not=$, $<$, $>$, $\leq$, $\geq$)}
			\State \textbf{return} P.name
		\EndIf 																		 
	\EndIf							 
\EndFor
\EndFunction

\end{algorithmic}

\newpage
\begin{algorithmic}[1]

\Function{EvaluateExpression}{TreeNode}										\Comment{Recursively evaluate the expression tree}
	\State left $\gets$ 0.0									
	\State right $\gets$ 0.0
	
	\If{TreeNode.left $==$ NULL OR TreeNode.right $==$ NULL}
		\State \textbf{return} TreeNode.value
	\EndIf
	
	\State left $\gets$ \Call{ReplaceVariables}{TreeNode.left}
	\State right $\gets$ \Call{ReplaceVariables}{TreeNode.right}
	
	\If{TreeNode.type is an operator}
		\State \textbf{return} left TreeNode.operator right					\Comment{Apply arithmetic operator (+, -, *, /, $\land{}$)}
	\EndIf
\EndFunction
\\
\end{algorithmic}

\begin{algorithmic}[1]

\Function{ReplaceVariables}{TreeNode}										\Comment{Recursively replace expression tree variables}
	\If{TreeNode $==$ NULL}
		\State \textbf{return}
	\EndIf
	\If{TreeNode.type is a variable}
		\If{TreeNode.value is in constants table}
			\State TreeNode.value $\gets$ numeric value in constants table 
		\EndIf
		\If{TreeNode.value is in local table}
			\State TreeNode.value $\gets$ numeric value in local table
		\EndIf
	\EndIf
	\State \Call{ReplaceVariables}{TreeNode.left}
	\State \Call{ReplaceVariables}{TreeNode.right}
\EndFunction


\end{algorithmic}

\begin{algorithmic}[1]

\Function{AddLocalVar}{call, def}										

\EndFunction

\end{algorithmic}